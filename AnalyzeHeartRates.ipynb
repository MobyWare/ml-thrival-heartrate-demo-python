{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix(array):\n",
    "    n = np.array([])\n",
    "    for x in array:\n",
    "        n = np.append(n, np.zeros((x-1)/100.0))\n",
    "        n = np.append(n, [1])\n",
    "    return n\n",
    "\n",
    "def printClusterMetrics(clusterModel, observations):\n",
    "    clusters = clusterModel.fit(observations)\n",
    "    centers = clusters.cluster_centers_indices_\n",
    "    labels = clusters.labels_\n",
    "    if centers is None or len(centers) < 1:\n",
    "        print(\"Clustering algorithm didn't converge.\")\n",
    "    else:        \n",
    "        silhouetteMetric = metrics.silhouette_score(observations, labels, metric='euclidean')\n",
    "        print(\\\n",
    "            'There are {} obervations and {} clusters, with a confidence of {}.\\nThe labels were: {}'.format(observations.shape[0], len(centers), silhouetteMetric, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,  13,  40,  46,  53,  69,  75,  78,  81,  90, 104, 112, 119, 122])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) data/alice1.txt. Both the spectrum: 129 and amplitude: 129 should had have the same length. The currnet # of samples is: 1.\n",
      " Amplitude (1st five): [  8.31841922e-06   4.62329127e-05   4.05553263e-05   2.75373388e-05\n",
      "   1.42692978e-05]\n",
      "2) data/eve1.txt. Both the spectrum: 129 and amplitude: 129 should had have the same length. The currnet # of samples is: 2.\n",
      " Amplitude (1st five): [  1.35029040e-05   5.44252765e-05   1.19388351e-04   5.80933853e-05\n",
      "   2.16519506e-05]\n",
      "3) data/bob1.txt. Both the spectrum: 129 and amplitude: 129 should had have the same length. The currnet # of samples is: 3.\n",
      " Amplitude (1st five): [  9.33411383e-06   4.05932607e-05   3.82830492e-05   1.59216068e-05\n",
      "   8.75379624e-06]\n",
      "4) data/bob2.txt. Both the spectrum: 129 and amplitude: 129 should had have the same length. The currnet # of samples is: 4.\n",
      " Amplitude (1st five): [  7.15253543e-06   3.24039377e-05   3.63528577e-05   2.25078209e-05\n",
      "   1.16273779e-05]\n",
      "5) data/alice2.txt. Both the spectrum: 129 and amplitude: 129 should had have the same length. The currnet # of samples is: 5.\n",
      " Amplitude (1st five): [  5.16656010e-06   2.15698056e-05   2.93981653e-05   1.59188152e-05\n",
      "   6.42818316e-06]\n",
      "There are 5 obervations and 3 clusters, with a confidence of 0.726256158727.\n",
      "The labels were: [0 1 2 2 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "samples = None\n",
    "files = ['data/alice1.txt', 'data/eve1.txt', 'data/bob1.txt', 'data/bob2.txt', 'data/alice2.txt']\n",
    "\n",
    "for index, filename in enumerate(files):\n",
    "    intervals = np.loadtxt(filename)\n",
    "    intervals = intervals[intervals < 2000][0:1000] \n",
    "    frequencySpectrum, amplitude = signal.welch(fix(intervals), 5, scaling='spectrum')\n",
    "    if samples is None:\n",
    "        samples = amplitude[np.newaxis]\n",
    "    else:\n",
    "        samples = np.concatenate((samples, amplitude[np.newaxis]), axis=0)\n",
    "    print (\\\n",
    "        '{}) {}. Both the spectrum: {} and amplitude: {} should had have the same length. The currnet # of samples is: {}.\\n Amplitude (1st five): {}'.\\\n",
    "        format(str(index + 1), filename, len(frequencySpectrum), len(amplitude), samples.shape[0], amplitude[0:5]))\n",
    "\n",
    "printClusterMetrics(AffinityPropagation(max_iter=5000), samples)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with clustering on heart beat intervals\n",
    "\n",
    "FFT really help. When we try to cluster on just the raw beat intervals the cluster cannot detect there are three individuals. It's good that it at least clusters the common ones.\n",
    "\n",
    "With FFT we cluster the like onces and can discrimiate the odd person out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) # features (expect 1000): 1000. Current # of samples is: 1.\n",
      " Intervals (1st five): \n",
      "1) # features (expect 1000): 1000. Current # of samples is: 2.\n",
      " Intervals (1st five): \n",
      "2) # features (expect 1000): 1000. Current # of samples is: 3.\n",
      " Intervals (1st five): \n",
      "3) # features (expect 1000): 1000. Current # of samples is: 4.\n",
      " Intervals (1st five): \n",
      "4) # features (expect 1000): 1000. Current # of samples is: 5.\n",
      " Intervals (1st five): \n",
      "There are 5 obervations and 2 clusters, with a confidence of 0.237648018209.\n",
      "The labels were: [1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "samples = None\n",
    "files = ['data/alice1.txt', 'data/eve1.txt', 'data/bob1.txt', 'data/bob2.txt', 'data/alice2.txt']\n",
    "message = \"{}) # features (expect 1000): {}. Current # of samples is: {}.\\n Intervals (1st five): \"\\\n",
    "        \"\"\n",
    "            \n",
    "for index, filename in enumerate(files):\n",
    "    intervals = np.loadtxt(filename)\n",
    "    intervals = intervals[intervals < 2000][0:1000] \n",
    "    #frequencySpectrum, amplitude = signal.welch(fix(intervals), 5, scaling='spectrum')\n",
    "    if samples is None:\n",
    "        samples = intervals[np.newaxis]\n",
    "    else:\n",
    "        samples = np.concatenate((samples, intervals[np.newaxis]), axis=0)\n",
    "    print (message.format(str(index), intervals.size, samples.shape[0], intervals[0:5],\\\n",
    "            np.average(intervals), np.max(intervals), np.min(intervals), np.std(intervals)))\n",
    "\n",
    "printClusterMetrics(AffinityPropagation(max_iter=5000), samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type is <type 'numpy.ndarray'> and the size is 1000.\n",
      "[ 784.  794.  838.  794.  778.]\n"
     ]
    }
   ],
   "source": [
    "intervals = np.loadtxt('data/alice1.txt')[0:1000]\n",
    "print('The type is {} and the size is {}.'.format(type(intervals), intervals.size))\n",
    "print(intervals[0:5])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
